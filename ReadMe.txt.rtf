{\rtf1\ansi\ansicpg1252\cocoartf2639
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica-Bold;\f1\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\margl1440\margr1440\vieww19200\viewh13260\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs48 \cf0 # Human Detection Camera App by Jonathan Heglin\
\
## Overview\
\

\f1\b0\fs36 This app uses the device's camera to detect and track humans in real-time using an CoreML image recognition model. Two versions of the YOLOv3 model are evaluated:\
\
- YOLOv3FP16 - The full YOLOv3 model converted to 16-bit floating point for optimization on mobile devices.\
\
- YOLOv3TinyFP16 - A smaller, compressed version of YOLOv3 that trades some accuracy for improved performance.
\f0\b\fs48 \
\
### Object Detection\
\

\f1\b0\fs36 Both models use a technique called You Only Look Once (YOLO) to detect multiple objects in an image. The image is divided into a grid and each grid cell predicts bounding boxes and class probabilities for potential objects. This allows the model to identify the location and classification of multiple objects in a single pass.\

\f0\b\fs48 \

\f1\b0\fs36 The models have been trained on a dataset of common objects including different human poses. At runtime, the device's camera stream is processed through the model frame-by-frame to identify candidate regions containing humans.\

\f0\b\fs48 \
### Object Tracking\
\

\f1\b0\fs36 In addition to detection, the app uses tracking to follow detected persons across consecutive frames. This helps smooth out erratic detections and improves consistency of the bounding boxes. \

\f0\b\fs48 \

\f1\b0\fs36 Tracks are ended if no match is found after several frames. The app smooths the bounding box coordinates over the lifetime of each track.\

\f0\b\fs48 \
### Model Evaluation\
\

\f1\b0\fs36 Two YOLO models has been tested for 3 provided videos. These YOLOv3 variants offer a tradeoff between accuracy and performance:\
\
- YOLOv3FP16 can detect smaller, partially obscured humans more accurately but runs slower. It offers the highest accuracy. it works better for video_2 generally in terms of detection speed and accuracy. \
\
- YOLOv3TinyFP16 has lower latency and can achieve near real-time performance but may miss some difficult human poses. It works better in full light.\
\
By leveraging CoreML's optimization and tracking, the app can deliver a good real-time human detection experience on iOS devices using state-of-the-art computer vision techniques.\
\
### 
\f0\b\fs48 App Structure\

\f1\b0\fs36 \
\pard\tx220\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\li720\fi-720\pardirnatural\partightenfactor0
\ls1\ilvl0\cf0 {\listtext	\uc0\u8226 	}An MVVM design pattern is used for communication between UI and models and handling the Detection and tracking logics. \
{\listtext	\uc0\u8226 	}At higher level protocol oriented programming method is used to focus on interacting between protocols instead of worrying about classes interactions (Camera service protocol implementation remained because of the lack of time).\
{\listtext	\uc0\u8226 	}VNCoreMLModel used to import and use all properties and methods of YOLO models. \
{\listtext	\uc0\u8226 	}Using camera interface in order to get input is my preference because I was not sure about giving input method (real time or recorded video).\
{\listtext	\uc0\u8226 	}Switching between Detection and Tracking condition is not perfectly handled, I needed time for that. \
{\listtext	\uc0\u8226 	}Checking distance of object center and phone screen center is used in order to make sure when triggering the action (Green Border)\
{\listtext	\uc0\u8226 	}Unfortunately there was not enough time to write unit tests for my code.\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \
\
}